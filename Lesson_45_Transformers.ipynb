{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "collapsed": true,
        "id": "YAUpUj3lEgaL",
        "outputId": "770625a5-56fc-4711-bb49-97350716e24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "6634df5cce6e4dfe87bb2b4b0de3ef8a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    RobertaTokenizerFast,\n",
        "    RobertaForSequenceClassification,\n",
        "    DistilBertTokenizerFast,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"review\"], truncation=True)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = torch.argmax(torch.tensor(logits), axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
        "\n",
        "def predict_sentiment(texts, batch_size=128, max_length=512):\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n",
        "    batch = texts[i:i+batch_size]\n",
        "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True,\n",
        "                       max_length=max_length).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    return all_preds, all_probs"
      ],
      "metadata": {
        "id": "qXPZ4e7usw6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DistilBert"
      ],
      "metadata": {
        "id": "yCu3sySyse2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "\n",
        "df_all = df_all.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_all[\"label\"] = df_all[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
        "\n",
        "train_df, val_df = train_test_split(df_all, test_size=0.1, random_state=42)\n",
        "train_dataset = Dataset.from_pandas(train_df[[\"review\", \"label\"]])\n",
        "val_dataset = Dataset.from_pandas(val_df[[\"review\", \"label\"]])\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"review\"])\n",
        "val_dataset = val_dataset.remove_columns([\"review\"])\n",
        "train_dataset.set_format(\"torch\")\n",
        "val_dataset.set_format(\"torch\")\n",
        "\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    dataloader_num_workers=2,\n",
        "    report_to=[],\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=64,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    #use_cpu=True,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "model.save_pretrained(\"./finetuned-distilbert-sentiment\")\n",
        "tokenizer.save_pretrained(\"./finetuned-distilbert-sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "nMb7yvlZYY90",
        "outputId": "1df49793-4254-44bb-c9e1-1f920e0d3dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-1073331516.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='820' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [820/820 21:39, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.239200</td>\n",
              "      <td>0.183361</td>\n",
              "      <td>0.929200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.190200</td>\n",
              "      <td>0.179660</td>\n",
              "      <td>0.934000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.082400</td>\n",
              "      <td>0.188229</td>\n",
              "      <td>0.935600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.100100</td>\n",
              "      <td>0.175690</td>\n",
              "      <td>0.937800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned-distilbert-sentiment/tokenizer_config.json',\n",
              " './finetuned-distilbert-sentiment/special_tokens_map.json',\n",
              " './finetuned-distilbert-sentiment/vocab.txt',\n",
              " './finetuned-distilbert-sentiment/added_tokens.json',\n",
              " './finetuned-distilbert-sentiment/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Roberta"
      ],
      "metadata": {
        "id": "sepCNtfRsmA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "\n",
        "df_all = df_all.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_all[\"label\"] = df_all[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
        "\n",
        "train_df, val_df = train_test_split(df_all, test_size=0.1, random_state=42)\n",
        "train_dataset = Dataset.from_pandas(train_df[[\"review\", \"label\"]])\n",
        "val_dataset = Dataset.from_pandas(val_df[[\"review\", \"label\"]])\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns([\"review\"])\n",
        "val_dataset = val_dataset.remove_columns([\"review\"])\n",
        "train_dataset.set_format(\"torch\")\n",
        "val_dataset.set_format(\"torch\")\n",
        "\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    report_to=[],\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=416,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=416,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=54,\n",
        "    per_device_eval_batch_size=54,\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=True,\n",
        "    dataloader_num_workers=2,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "model.save_pretrained(\"./finetuned-roberta-sentiment\")\n",
        "tokenizer.save_pretrained(\"./finetuned-roberta-sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Zn-t-frufizx",
        "outputId": "969744f5-1352-46e2-e5f5-600ae2c17c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-24-2709801614.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1668' max='1668' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1668/1668 40:02, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>416</td>\n",
              "      <td>0.195100</td>\n",
              "      <td>0.160606</td>\n",
              "      <td>0.938400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>832</td>\n",
              "      <td>0.154700</td>\n",
              "      <td>0.141089</td>\n",
              "      <td>0.949600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1248</td>\n",
              "      <td>0.083000</td>\n",
              "      <td>0.181984</td>\n",
              "      <td>0.939600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1664</td>\n",
              "      <td>0.079700</td>\n",
              "      <td>0.152651</td>\n",
              "      <td>0.953600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned-roberta-sentiment/tokenizer_config.json',\n",
              " './finetuned-roberta-sentiment/special_tokens_map.json',\n",
              " './finetuned-roberta-sentiment/vocab.json',\n",
              " './finetuned-roberta-sentiment/merges.txt',\n",
              " './finetuned-roberta-sentiment/added_tokens.json',\n",
              " './finetuned-roberta-sentiment/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Проверяем Roberta\n",
        "\n",
        "df_all = pd.read_csv('/content/IMDB Dataset.csv')\n",
        "\n",
        "df_all = df_all.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_all[\"label\"] = df_all[\"sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
        "\n",
        "model_path = \"/content/finetune-roberta-sentiment\"\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_path)\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "train_df, val_df = train_test_split(df_all, test_size=0.1, random_state=42)\n",
        "\n",
        "preds, probs = predict_sentiment(val_df[\"review\"].tolist())\n",
        "\n",
        "true_labels = val_df[\"label\"].tolist()\n",
        "acc = accuracy_score(true_labels, preds)\n",
        "print(f\"\\n✅ Accuracy: {acc:.4f}\")\n",
        "print(classification_report(true_labels, preds, target_names=[\"negative\", \"positive\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqtukptkxvxS",
        "outputId": "40ceea8e-5103-4e4c-b093-3dd201720292",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 40/40 [2:31:57<00:00, 227.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Accuracy: 0.9536\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.96      0.95      0.95      2512\n",
            "    positive       0.95      0.96      0.95      2488\n",
            "\n",
            "    accuracy                           0.95      5000\n",
            "   macro avg       0.95      0.95      0.95      5000\n",
            "weighted avg       0.95      0.95      0.95      5000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "\n",
        "import os\n",
        "\n",
        "# === Настройки CUDA ===\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === Данные ===\n",
        "df = pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "df['label'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
        "train_df, val_df = train_test_split(df, test_size=0.05, random_state=42)\n",
        "\n",
        "# === Токенизатор ===\n",
        "SPECIAL_TOKENS = [\"[PAD]\", \"[UNK]\", \"[CLS]\"]\n",
        "if not os.path.exists(\"my_tokenizer.json\"):\n",
        "    tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
        "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "    trainer = trainers.BpeTrainer(vocab_size=8000, special_tokens=SPECIAL_TOKENS)\n",
        "    tokenizer.train_from_iterator(train_df[\"review\"].tolist(), trainer)\n",
        "    tokenizer.save(\"my_tokenizer.json\")\n",
        "\n",
        "tokenizer = Tokenizer.from_file(\"my_tokenizer.json\")\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "\n",
        "# === Гиперпараметры ===\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 4\n",
        "D_MODEL = 384\n",
        "N_HEADS = 8\n",
        "N_LAYERS = 4\n",
        "\n",
        "# === Датасет ===\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = tokenizer.encode(self.texts[idx])\n",
        "        input_ids = [tokenizer.token_to_id(\"[CLS]\")] + encoded.ids[:MAX_LEN - 1]\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        pad_len = MAX_LEN - len(input_ids)\n",
        "        input_ids += [tokenizer.token_to_id(\"[PAD]\")] * pad_len\n",
        "        attention_mask += [0] * pad_len\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids),\n",
        "            \"attention_mask\": torch.tensor(attention_mask),\n",
        "            \"label\": torch.tensor(self.labels[idx]),\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "train_dataset = IMDBDataset(train_df[\"review\"].tolist(), train_df[\"label\"].tolist())\n",
        "val_dataset = IMDBDataset(val_df[\"review\"].tolist(), val_df[\"label\"].tolist())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=2)\n",
        "\n",
        "# === Positional Encoding ===\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# === Модель ===\n",
        "class MiniTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=4 * d_model,\n",
        "            dropout=0.2,\n",
        "            activation='gelu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.cls_fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.embedding(input_ids)\n",
        "        x = self.positional_encoding(x)\n",
        "        attn_mask = ~attention_mask.bool()\n",
        "        x = self.transformer(x, src_key_padding_mask=attn_mask)\n",
        "        cls_token = x[:, 0]\n",
        "        out = self.dropout(self.norm(cls_token))\n",
        "        return self.cls_fc(out)\n",
        "\n",
        "# === Инициализация ===\n",
        "model = MiniTransformer(vocab_size, D_MODEL, N_HEADS, N_LAYERS, 2).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# === Обучение ===\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "    for step, batch in enumerate(loop):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # === Каждые 300 шагов: mini-validation ===\n",
        "        if (step + 1) % 300 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_preds, val_labels = [], []\n",
        "                for val_batch in list(val_loader)[:10]:  # Быстрая проверка\n",
        "                    ids = val_batch[\"input_ids\"].to(device)\n",
        "                    mask = val_batch[\"attention_mask\"].to(device)\n",
        "                    lbls = val_batch[\"label\"].to(device)\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        outputs = model(ids, mask)\n",
        "                    preds = torch.argmax(outputs, dim=1)\n",
        "                    val_preds.extend(preds.cpu().numpy())\n",
        "                    val_labels.extend(lbls.cpu().numpy())\n",
        "                val_acc = accuracy_score(val_labels, val_preds)\n",
        "            loop.set_postfix(loss=loss.item(), val_acc=val_acc)\n",
        "            model.train()\n",
        "\n",
        "    # === Полная валидация после эпохи ===\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbls = batch[\"label\"].to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(ids, mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(lbls.cpu().numpy())\n",
        "\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"\\n✅ Epoch {epoch+1} Validation Accuracy: {epoch_acc:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU77gOK1EyO4",
        "outputId": "e234e688-00b8-4a83-992f-c375a7dda368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-646233910.py:119: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "Epoch 1:   0%|          | 0/372 [00:00<?, ?it/s]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1:  80%|████████  | 299/372 [02:12<00:31,  2.28it/s]/tmp/ipython-input-5-646233910.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1:  81%|████████  | 300/372 [02:16<01:41,  1.42s/it, loss=0.493, val_acc=0.803]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1: 100%|██████████| 372/372 [02:47<00:00,  2.22it/s, loss=0.493, val_acc=0.803]\n",
            "/tmp/ipython-input-5-646233910.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 1 Validation Accuracy: 0.8256\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:   0%|          | 0/372 [00:00<?, ?it/s]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 2:  80%|████████  | 299/372 [02:11<00:31,  2.29it/s]/tmp/ipython-input-5-646233910.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 2:  81%|████████  | 300/372 [02:16<02:02,  1.70s/it, loss=0.362, val_acc=0.848]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 2: 100%|██████████| 372/372 [02:47<00:00,  2.21it/s, loss=0.362, val_acc=0.848]\n",
            "/tmp/ipython-input-5-646233910.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 2 Validation Accuracy: 0.8608\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3:   0%|          | 0/372 [00:00<?, ?it/s]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 3:  80%|████████  | 299/372 [02:12<00:31,  2.28it/s]/tmp/ipython-input-5-646233910.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 3:  81%|████████  | 300/372 [02:16<01:41,  1.41s/it, loss=0.28, val_acc=0.866]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 3: 100%|██████████| 372/372 [02:47<00:00,  2.22it/s, loss=0.28, val_acc=0.866]\n",
            "/tmp/ipython-input-5-646233910.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 3 Validation Accuracy: 0.8780\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 4:   0%|          | 0/372 [00:00<?, ?it/s]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 4:  80%|████████  | 299/372 [02:11<00:32,  2.27it/s]/tmp/ipython-input-5-646233910.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 4:  81%|████████  | 300/372 [02:16<01:59,  1.66s/it, loss=0.297, val_acc=0.878]/tmp/ipython-input-5-646233910.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 4: 100%|██████████| 372/372 [02:47<00:00,  2.22it/s, loss=0.297, val_acc=0.878]\n",
            "/tmp/ipython-input-5-646233910.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 4 Validation Accuracy: 0.8732\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "\n",
        "import os\n",
        "\n",
        "# === Настройки CUDA ===\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === Данные ===\n",
        "df = pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "df['label'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
        "train_df, val_df = train_test_split(df, test_size=0.05, random_state=42)\n",
        "\n",
        "# === Токенизатор ===\n",
        "SPECIAL_TOKENS = [\"[PAD]\", \"[UNK]\", \"[CLS]\"]\n",
        "if not os.path.exists(\"my_tokenizer.json\"):\n",
        "    tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
        "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "    trainer = trainers.BpeTrainer(vocab_size=16000, special_tokens=SPECIAL_TOKENS)\n",
        "    tokenizer.train_from_iterator(train_df[\"review\"].tolist(), trainer)\n",
        "    tokenizer.save(\"my_tokenizer.json\")\n",
        "\n",
        "tokenizer = Tokenizer.from_file(\"my_tokenizer.json\")\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "\n",
        "# === Гиперпараметры ===\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 16\n",
        "D_MODEL = 192\n",
        "N_HEADS = 4\n",
        "N_LAYERS = 2\n",
        "\n",
        "# === Датасет ===\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = tokenizer.encode(self.texts[idx])\n",
        "        input_ids = [tokenizer.token_to_id(\"[CLS]\")] + encoded.ids[:MAX_LEN - 1]\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        pad_len = MAX_LEN - len(input_ids)\n",
        "        input_ids += [tokenizer.token_to_id(\"[PAD]\")] * pad_len\n",
        "        attention_mask += [0] * pad_len\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(input_ids),\n",
        "            \"attention_mask\": torch.tensor(attention_mask),\n",
        "            \"label\": torch.tensor(self.labels[idx]),\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "train_dataset = IMDBDataset(train_df[\"review\"].tolist(), train_df[\"label\"].tolist())\n",
        "val_dataset = IMDBDataset(val_df[\"review\"].tolist(), val_df[\"label\"].tolist())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=2)\n",
        "\n",
        "# === Positional Encoding ===\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# === Модель ===\n",
        "class MiniTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, nhead, num_layers, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=4 * d_model,\n",
        "            dropout=0.3,\n",
        "            activation='gelu',\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.cls_fc = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.embedding(input_ids)\n",
        "        x = self.positional_encoding(x)\n",
        "        attn_mask = ~attention_mask.bool()\n",
        "        x = self.transformer(x, src_key_padding_mask=attn_mask)\n",
        "        cls_token = x[:, 0]\n",
        "        out = self.dropout(self.norm(cls_token))\n",
        "        return self.cls_fc(out)\n",
        "\n",
        "# === Инициализация ===\n",
        "model = MiniTransformer(vocab_size, D_MODEL, N_HEADS, N_LAYERS, 2).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# === Обучение ===\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "    for step, batch in enumerate(loop):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # === Каждые 300 шагов: mini-validation ===\n",
        "        if (step + 1) % 1000 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_preds, val_labels = [], []\n",
        "                for val_batch in list(val_loader)[:10]:  # Быстрая проверка\n",
        "                    ids = val_batch[\"input_ids\"].to(device)\n",
        "                    mask = val_batch[\"attention_mask\"].to(device)\n",
        "                    lbls = val_batch[\"label\"].to(device)\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        outputs = model(ids, mask)\n",
        "                    preds = torch.argmax(outputs, dim=1)\n",
        "                    val_preds.extend(preds.cpu().numpy())\n",
        "                    val_labels.extend(lbls.cpu().numpy())\n",
        "                val_acc = accuracy_score(val_labels, val_preds)\n",
        "            loop.set_postfix(loss=loss.item(), val_acc=val_acc)\n",
        "            model.train()\n",
        "\n",
        "    # === Полная валидация после эпохи ===\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbls = batch[\"label\"].to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(ids, mask)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(lbls.cpu().numpy())\n",
        "\n",
        "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"\\n✅ Epoch {epoch+1} Validation Accuracy: {epoch_acc:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jJtEAvV5gRe",
        "outputId": "d8619c05-6d19-4f9e-dc8f-19b7f05e6fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-3446505604.py:119: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "Epoch 1:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1: 100%|██████████| 186/186 [00:46<00:00,  4.03it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 1 Validation Accuracy: 0.7432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 2: 100%|██████████| 186/186 [00:48<00:00,  3.84it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 2 Validation Accuracy: 0.7972\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 3: 100%|██████████| 186/186 [00:48<00:00,  3.83it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 3 Validation Accuracy: 0.8416\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 4:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 4: 100%|██████████| 186/186 [00:47<00:00,  3.91it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 4 Validation Accuracy: 0.8420\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 5: 100%|██████████| 186/186 [00:47<00:00,  3.89it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 5 Validation Accuracy: 0.8672\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 6:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 6: 100%|██████████| 186/186 [00:48<00:00,  3.86it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 6 Validation Accuracy: 0.8692\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 7:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 7: 100%|██████████| 186/186 [00:48<00:00,  3.87it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 7 Validation Accuracy: 0.8616\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 8:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 8: 100%|██████████| 186/186 [00:48<00:00,  3.87it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 8 Validation Accuracy: 0.8752\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 9:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 9: 100%|██████████| 186/186 [00:47<00:00,  3.89it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 9 Validation Accuracy: 0.8768\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 10:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 10: 100%|██████████| 186/186 [00:48<00:00,  3.84it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 10 Validation Accuracy: 0.8748\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 11:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 11: 100%|██████████| 186/186 [00:48<00:00,  3.84it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 11 Validation Accuracy: 0.8800\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 12:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 12: 100%|██████████| 186/186 [00:47<00:00,  3.95it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 12 Validation Accuracy: 0.8832\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 13:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 13: 100%|██████████| 186/186 [00:47<00:00,  3.94it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 13 Validation Accuracy: 0.8780\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 14:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 14: 100%|██████████| 186/186 [00:47<00:00,  3.89it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 14 Validation Accuracy: 0.8808\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 15:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 15: 100%|██████████| 186/186 [00:47<00:00,  3.90it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 15 Validation Accuracy: 0.8776\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 16:   0%|          | 0/186 [00:00<?, ?it/s]/tmp/ipython-input-4-3446505604.py:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 16: 100%|██████████| 186/186 [00:48<00:00,  3.85it/s]\n",
            "/tmp/ipython-input-4-3446505604.py:165: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Epoch 16 Validation Accuracy: 0.8808\n",
            "\n"
          ]
        }
      ]
    }
  ]
}